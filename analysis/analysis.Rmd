---
title: "Bo-NO-bouba-kiki: Picture-word mapping but not sound symbolism in a language trained bonobo"
subtitle: "Supplementary material"
author: "Konstantina Margiotoudi, Manuel Bohn, Natalie Schwob, Jared Taglialatela, Friedemann Pulvermüller, Amanda Epping, Ken Schweller, Matthias Allritz"
output: 
  bookdown::html_document2:
    toc: yes
    toc_float: true
    fig_caption: yes
    #code_folding: hide
    number_sections: false
  bookdown::pdf_document2:
    toc: yes 
    number_sections: false    
#bibliography: library.bib
#csl: pnas.csl
#header-includes:
#  \usepackage{caption}
#  \renewcommand{\figurename}{Supplementary Figure}
#  \renewcommand{\tablename}{Supplementary Table}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, warning = F, message = F, size="small")

library(tidyverse)
library(brms)
library(broom)
library(ggthemes)
library(lme4)
library(tidyboot)
library(ggpubr)
library(tidybayes)
library(coda)
library(knitr)

hdi_upper<- function(s){
  m <- HPDinterval(mcmc(s))
  return(m["var1","upper"])
}

hdi_lower<- function(s){
  m <- HPDinterval(mcmc(s))
  return(m["var1","lower"])
}
```


```{r, include=F}
data <- read_csv("../data/data.csv")
```

# Descriptives

## Number of Trials

Number of trials per condition. There were 30 sessions in total, each with 10 test trials. There are 2 regular trials missing, because of a software error in session 1 and 2 (see main paper for detail). 

```{r}
t1 <- data %>%
  group_by(condition)%>%
  summarise(n = n())%>%
  kable()

knitr::kable(t1, caption = "Number of trials per condition.", digits = 2, align = "l")
```

## Reaction times

Visualize reaction time by correct choice and trial type to check if responses were slower / faster in test trials compared to regular trials. Responses seemed to be faster in test trials, but the two distributions still overlap considerably. 

```{r, fig.height = 3, fig.cap = "Reactions times for regular and test trials split by correct and incorrect responses.", out.width="100%"}
rt_data <- data%>%
  mutate(correct = ifelse(correct == 1, "correct", "incorrect"))

rt_plot <- ggplot(rt_data, aes(x = RT, col = condition, fill = condition, lty = correct))+
  geom_density(alpha = .3)+
  xlim(0,6000)+
  xlab("Reaction Time")+
  ylab("")+
  scale_color_colorblind(name = "Condition")+
  scale_fill_colorblind(name = "Condition")+
  scale_linetype_discrete(name = "Choice")+
  theme_minimal()+
  theme(axis.text.y = element_blank(),
        axis.ticks.y  = element_blank(),
        legend.position = c(0.7,0.6),
        legend.direction = "vertical",
        legend.box = "horizontal")
```

Change in reaction time over time. Reaction times are relatively stable across time and changed in similar ways in regular and test trials.

```{r, fig.height = 3, fig.cap = "Reactions time across trials (continous across sessions) for regular and test trials. light dots represent individual trials. Regression line gives a smoothed conditional mean.", out.width="100%"}
rt_data%>%
  group_by(condition)%>%
  mutate(trial_cont = 1:length(trial))%>%
  ggplot(aes(x = trial_cont, y = RT, col = condition))+
  geom_point(alpha = .25)+
  geom_smooth(col = "firebrick", method = "loess")+
  facet_grid(~condition, scales = "free_x")+
  labs(x = "Trial (continous across sessions)", y = "Reaction time (ms)")+
  scale_color_colorblind()+
  theme_minimal()
```

# Results

## Statistical analysis

```{r}
test_data <- data %>%
  filter(condition == "test")%>%
  mutate(z_trial = scale(cont_trial))

regular_data <- data %>%
  filter(condition == "regular")%>%
  mutate(z_trial = scale(cont_trial))

```

### Test trials 

#### Comparison to chance

We used a Bayesian generalized linear mixed model to analyze performance. Our model hat the following structure: 

`correct ~ 1 + (z_trial | SampleSound )`

In this a model, the intercept models the average rate of correct responses in link space. A value of 0 in link space corresponds to a proportion of correct choices of 0.5. Thus, we inferred that if the 95% credible interval around the intercept did not include 0, performance was reliably above chance.

All models use default priors as implemented in the `brms` package. 

```{r, cache = T}
# model takes a minute or two to initialize and run.
# load rds file if you don't want to wait or if you want to reproduce the exact numbers in the manuscript

# bm_test <- brm(correct ~ 1 + (z_trial | SampleSound ), # + (z_trial | shape_combination),
#           data = test_data,
#           family = bernoulli(),
#           cores = 4,
#           chains = 4,
#           iter = 5000,
#           control = list(adapt_delta = 0.95))

#saveRDS(bm_test, "saves/model_test.rds")

bm_test <-readRDS("saves/model_test.rds")
```

```{r, fig.cap = "Estimate for intercept term (with 95 \\% credible interval) in the model for test trials. Dashed line shows chance level (in link space).", out.width="100%", fig.height = 3}
bm_test%>%
  spread_draws(b_Intercept)%>%
  ggplot(aes(x = b_Intercept, fill = stat(x < -0.08 | x > 0.41))) +
  stat_halfeye(alpha = .7)+
  geom_vline(xintercept = 0, linetype = "dashed") +
  labs("Intercept", y = "Density")+
  scale_fill_manual(values = c("gray80", "firebrick"), name = "95% Credible intervall", labels = c("< 2.5% | > 97.5%","2.5% - 97.5%"))+
  guides(fill = F)+
  theme_minimal()
```

##### Prior sensitivity analysis

Here we explore the effect of different prior distributions for the intercept estimate on the results. The default prior in `brms` is `student_t(3, 0, 2.5)`. We compare this to three other priors. A weak prior `normal(0, 10)`, a medium prior `normal(0, 5)`, and a strong prior `normal(0, 1)`.

```{r}
# weak_prior <- prior(normal(0, 10), class="Intercept")
# medium_prior <- prior(normal(0, 5), class="Intercept")
# strong_prior <- prior(normal(0, 1), coef="Intercept")
# 
# bm_test_weak_prior <- brm(correct ~ 1 + (z_trial | SampleSound ),
#           data = test_data,
#           family = bernoulli(),
#           cores = 4,
#           chains = 4,
#           prior = weak_prior,
#           iter = 5000,
#           control = list(adapt_delta = 0.95))
# 
# saveRDS(bm_test_weak_prior, "saves/model_test_weak_prior.rds")
# 
# bm_test_weak_prior <-readRDS("saves/model_test_weak_prior.rds")
# 
# bm_test_medium_prior <- brm(correct ~ 1 + (z_trial | SampleSound ),
#           data = test_data,
#           family = bernoulli(),
#           cores = 4,
#           chains = 4,
#           prior = medium_prior,
#           iter = 5000,
#           control = list(adapt_delta = 0.95))
# 
# saveRDS(bm_test_medium_prior, "saves/model_test_medium_prior.rds")
# 
# bm_test_medium_prior <-readRDS("saves/model_test_medium_prior.rds")
# 
# bm_test_strong_prior <- brm(correct ~ 1 + (z_trial | SampleSound ),
#           data = test_data,
#           family = bernoulli(),
#           cores = 4,
#           chains = 4,
#           prior = medium_prior,
#           iter = 5000,
#           control = list(adapt_delta = 0.95))
# 
# saveRDS(bm_test_strong_prior, "saves/model_test_strong_prior.rds")
# 
# bm_test_strong_prior <-readRDS("saves/model_test_strong_prior.rds")
# 
# prior_plot <- bind_rows(
#   fixef(bm_test)%>%as_tibble()%>%mutate(Prior = "default"),
#   fixef(bm_test_weak_prior)%>%as_tibble()%>%mutate(Prior = "weak"),
#   fixef(bm_test_medium_prior)%>%as_tibble()%>%mutate(Prior = "medium"),
#   fixef(bm_test_strong_prior)%>%as_tibble()%>%mutate(Prior = "strong")
# )
# 
# saveRDS(prior_plot, "saves/prior_sensitivity.rds")

prior_plot <- readRDS("saves/prior_sensitivity.rds")
```

```{r, fig.cap = "Estimate for intercept term (with 95 \\% confidence interval) in the model for test trials with different prior distributions. Dashed line shows chance level (in link space).", out.width="100%", fig.height = 3}

prior_plot%>%
  mutate(Prior = factor(Prior, levels = c("default", "weak","medium","strong")))%>%
  ggplot(aes(x = Prior, y = Estimate))+
  geom_hline(yintercept = 0, lty = 2, alpha = .75)+
  geom_pointrange(aes(ymin = Q2.5, ymax = Q97.5))+
  labs(y = "Model intercept")+
  ylim(-0.5, 0.5)+
  theme_minimal()
```

##### Subset analysis

In McCormick et al. (2015), some pseudo words were rated as more sound symbolic than others. These words were: `keke`,`kiki`,`pepe`,`pipi`,`lulu`,`lolo`,`mumu`,`momo`,`nono`,`nunu`. Here we re-run the model on a subset of the test trials that included only these pseudo words. 

This reduces the number of trials to `r length(test_data_sel$SampleSound)`.

```{r}
# sel_words = c("keke","kiki","pepe","pipi","lulu","lolo","mumu","momo","nono","nunu")
# 
# test_data_sel <- test_data%>%
#   mutate(SampleSound = substr(SampleSound, 1, nchar(SampleSound)-4))%>%
#   filter(SampleSound %in% sel_words)
# 
# bm_test_sel <- brm(correct ~ 1 + (z_trial | SampleSound ),
#           data = test_data_sel,
#           family = bernoulli(),
#           cores = 4,
#           chains = 4,
#           iter = 5000,
#           control = list(adapt_delta = 0.95))
# 
# saveRDS(bm_test_sel, "saves/model_test_sel.rds")
# 
# bm_test_sel <-readRDS("saves/model_test_sel.rds")
# 
# sel_plot <- bind_rows(
#   fixef(bm_test)%>%as_tibble()%>%mutate(Data = "all trials"),
#   fixef(bm_test_sel)%>%as_tibble()%>%mutate(Data = "subset")
# )
# 
# saveRDS(sel_plot, "saves/sel_plot.rds")

sel_plot <- readRDS("saves/sel_plot.rds")

```

```{r, fig.cap = "Estimate for intercept term (with 95 \\% confidence interval) in the model for test trials based on all trials (left) and a subset of trials with words that had high sound symbolic ratings in McCormick et al. (2015). Dashed line shows chance level (in link space).", out.width="100%", fig.height = 3}

sel_plot%>%
  ggplot(aes(x = Data, y = Estimate))+
  geom_hline(yintercept = 0, lty = 2, alpha = .75)+
  geom_pointrange(aes(ymin = Q2.5, ymax = Q97.5))+
  labs(y = "Model intercept")+
  ylim(-0.7, 0.7)+
  theme_minimal()
```

#### Shape preference

In test trials, Kanzi either had to match a round sound to a round shape or a edgy sound to a edgy shape to be correct. 

```{r, cache = T}
# load .rds file if you don't want to run the model

# bm_shape <- brm(correct ~ test_shape + (z_trial | SampleSound ), #+ (z_trial | shape_combination),
#           data = test_data,
#           family = bernoulli(),
#           cores = 4,
#           chains = 4,
#           iter = 5000,
#           control = list(adapt_delta = 0.95))

#saveRDS(bm_shape, "saves/model_shape.rds")

bm_shape <-readRDS("saves/model_shape.rds")

```

```{r, fig.cap = "Posterior estimates (with 95 \\% credible interval) for test trials with round or edgy shapes. Dashed line shows chance level (in link space).", out.width="100%", fig.height=4}
bm_shape%>%
  spread_draws(b_Intercept,b_test_shaperound)%>%
  mutate(edgy = b_Intercept,
         round = b_Intercept + b_test_shaperound)%>%
  select(round, edgy)%>%
  gather(test_shape, value)%>%
  ggplot(aes(x = value, y = test_shape)) +
  stat_halfeye(alpha = .7)+
  geom_vline(xintercept = 0, linetype = "dashed") +
  labs(x = "Model estimate", y = "Shape")+
  scale_fill_manual(values = c("gray80", "firebrick"), name = "95% Credible intervall", labels = c("< 2.5% | > 97.5%","2.5% - 97.5%"))+
  guides(fill = F)+
  theme_minimal()
```

### Regular trials

#### Comparison to chance

```{r, cache = T}
# model takes long time to run

# bm_regular <- brm(correct ~ 1 + (z_trial | SampleSound ),# + (z_trial | shape_combination),
#           data = regular_data,
#           family = bernoulli(),
#           cores = 4,
#           chains = 4,
#           iter = 5000,
#           control = list(adapt_delta = 0.99, max_treedepth = 20))

#saveRDS(bm_regular, "saves/model_regular.rds")

bm_regular <- readRDS("saves/model_regular.rds")
```


```{r}
bm_regular%>%
  spread_draws(b_Intercept)%>%
  ggplot(aes(x = b_Intercept, fill = stat(x < 1.71 | x > 2.30))) +
  stat_halfeye(alpha = .7)+
  geom_vline(xintercept = 0, linetype = "dashed") +
  xlab("Intercept")+
  scale_fill_manual(values = c("gray80", "firebrick"), name = "95% Credible intervall", labels = c("< 2.5% | > 97.5%","2.5% - 97.5%"))+
  guides(fill = F)+
  theme_minimal()
```


# Visualizations for manuscript

```{r, cache = T}
# data from individual sessions
plot_session <- data%>%
  group_by(session,condition)%>%
  tidyboot_mean(col = correct)

# model estimates
model_est <- bind_rows(
  fixef(bm_test)%>%as_tibble()%>%mutate(condition = "test"),
  fixef(bm_regular)%>%as_tibble()%>%mutate(condition = "regular"),
)%>%
  mutate(mean = plogis(Estimate),
         uci = plogis(Q2.5),
         lci = plogis(Q97.5))
  

res_plot <- ggplot()+
  geom_hline(yintercept = 0.5, lty = 2)+
  geom_jitter(data = plot_session, aes(x= condition, y = mean, col = condition), alpha = 0.2, width = 0.1, height = 0)+
  geom_pointrange(data = model_est, aes(x = condition, y = mean, ymax = uci, ymin = lci, col = condition),pch = 5)+
  ylim(0,1)+
  ylab("Proportion correct")+
  xlab("Condition")+
  scale_color_colorblind(name = "Condition")+
  guides(col = F)+
  theme_minimal()

sess_plot <- ggplot(plot_session, aes(x = session, col = condition))+
  geom_hline(yintercept = 0.5, lty = 2)+
  geom_point(aes(y = mean))+
  #geom_pointrange(aes(y = mean, ymax = ci_upper, ymin = ci_lower), pch = 5)+
  geom_line(aes(y= mean, col = condition))+
  ylim(0,1)+
  #facet_grid(condition~.)+
  ylab("Prop. correct")+
  xlab("Session")+
  scale_color_colorblind(name = "Condition")+
  theme_minimal()+
  theme(legend.position = c(0.5,0.1),
        legend.direction = "horizontal")


```

```{r, cache=T}
plot1 <- data%>%
  filter(condition == "test")%>%
  group_by(session, test_shape)%>%
  summarise(mean = mean(correct))

shape_est <- bm_shape%>%
  spread_draws(b_Intercept,b_test_shaperound)%>%
  mutate(edgy = b_Intercept,
         round = b_Intercept + b_test_shaperound)%>%
  select(round, edgy)%>%
  gather(test_shape, value)%>%
  group_by(test_shape)%>%
  summarise(mean = mean(value),
            uci = hdi_upper(value),
            lci = hdi_lower(value))%>%
  mutate_if(is.numeric, plogis)


shape_plot <- ggplot()+
  geom_hline(yintercept = 0.5, lty = 2)+
  geom_jitter(data = plot1, aes(x= test_shape, y = mean, col = test_shape), alpha = 0.2, width = 0.1, height = 0)+
  geom_pointrange(data = shape_est, aes(x = test_shape, y = mean, ymax = uci, ymin = lci, col = test_shape), pch = 5)+
  #geom_line(aes(y= mean, col = shape))+
  ylim(0,1)+
  ylab("Prop. correct")+
  xlab("Shape")+
  scale_color_ptol()+
  guides(col = F)+
  theme_minimal()
```

```{r, fig.cap="(A) Proportion of correct choices in regular and test trials. (B) Distribution of reaction times in regular and test trials for correct and incorrect choices. (C) Proportion of correct choices in each session for regular and test trials. (D) Proportion of correct choices in test trials with either edgy or round target shapes. In A and D: Diamonds and error bars represent the mean and 95\\% CrI based on the models’ posterior distribution. Transparent dots show horizontally jittered session means of the data.", out.width="100%", fig.height=6}

ggarrange(
  
  res_plot,
  
  ggarrange(
    rt_plot,
    
    ggarrange(
    sess_plot,
    shape_plot,
    nrow = 1,
    ncol = 2,
    widths = c(1.5,1),
    labels = c("C","D")
    ),
    nrow = 2,
    ncol = 1,
    labels = c("B","")),
  nrow = 1,
  ncol = 2,
  labels = c("A",""),
  widths = c(1,1.3)
)

#ggsave("figures/results.png", height = 3, width = 7, scale = 1.4)
```



